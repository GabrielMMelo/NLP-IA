{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordEmbeddings\n",
    "In this notebook we'll create a word embedding (using Gensim) representation of a corpus of texts in English. Also, we'll visualize the representation using T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "filename = \"dataset/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset_link = \"http://ai.stanford.edu/~amaas/data/sentiment/{}\".format(\"aclImdb_v1.tar.gz\")\n",
    "try:\n",
    "    os.mkdir(\"dataset\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    file = wget.download(dataset_link, out='dataset/aclImdb_v1.tar.gz')\n",
    "\n",
    "    tar = tarfile.open(filename, \"r:gz\")\n",
    "    tar.extractall(\"dataset\")\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/aclImdb'\n",
    "train_positive_files = ['train/pos/'+f for f in os.listdir(dataset_path+'/train/pos') \\\n",
    "                        if os.path.isfile(os.path.join(dataset_path+'/train/pos', f))]\n",
    "\n",
    "train_negative_files = ['train/neg/'+f for f in os.listdir(dataset_path+'/train/neg') \\\n",
    "                        if os.path.isfile(os.path.join(dataset_path+'/train/neg', f))]\n",
    "\n",
    "test_positive_files = ['test/pos/'+f for f in os.listdir(dataset_path+'/test/pos') \\\n",
    "                       if os.path.isfile(os.path.join(dataset_path+'/test/pos', f))]\n",
    "\n",
    "test_negative_files = ['test/neg/'+f for f in os.listdir(dataset_path+'/test/neg') \\\n",
    "                       if os.path.isfile(os.path.join(dataset_path+'/test/neg', f))]\n",
    "\n",
    "all_files = list(set().union(train_positive_files,train_negative_files, test_positive_files, test_negative_files))\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for file in all_files:\n",
    "    with open(os.path.join(dataset_path, file), 'r') as text_file:\n",
    "        corpus.append(text_file.readlines()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pre-process corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_texts(text):\n",
    "    text = REPLACE_NO_SPACE.sub(\"\", text.lower())\n",
    "    text = REPLACE_WITH_SPACE.sub(\" \", text)\n",
    "    \n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from math import floor\n",
    "\n",
    "agents = 4\n",
    "chunksize = floor(len(corpus)/4)\n",
    "with Pool(processes=agents) as pool:\n",
    "    processed_corpus = pool.map(preprocess_texts, corpus, chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'beautiful', 'story', 'of', 'stardust', 'is', 'written', 'by', 'by', 'neil', 'gaiman', 'writer', 'of', 'mirrormask', 'and', 'its', 'really', 'a', 'good', 'story', 'i', 'think', 'it', 'would', 'appeal', 'to', 'any', 'labyrinth', 'princess', 'bride', 'or', '10th', 'kingdom', 'fan', 'and', 'yet', 'its', 'totally', 'unique', 'and', 'stands', 'up', 'on', 'its', 'own', 'and', 'i', 'feel', 'the', 'film', 'adaptation', 'of', 'this', 'story', 'has', 'a', 'far', 'better', 'ending', 'than', 'what', 'was', 'presented', 'in', 'the', 'original', 'novel', 'by', 'neil', 'gaiman', 'i', 'wont', 'spoil', 'it', 'for', 'you', 'the', 'main', 'character', 'tristan', 'tristran', 'in', 'the', 'novel', 'is', 'the', 'son', 'of', 'a', 'mortal', 'and', 'a', 'faerie', 'slave', 'kept', 'by', 'a', 'witch', 'in', 'the', 'realm', 'of', 'faerie', 'the', 'story', 'begins', 'in', 'a', 'town', 'near', 'a', 'wall', 'that', 'separates', 'the', 'magical', 'world', 'from', 'the', 'human', 'world', 'when', 'there', 'is', 'a', 'falling', 'star', 'tristan', 'promises', 'to', 'retrieve', 'it', 'for', 'a', 'girl', 'he', 'is', 'infatuated', 'with', 'he', 'is', 'unaware', 'that', 'the', 'star', 'has', 'taken', 'the', 'form', 'of', 'a', 'girl', 'in', 'the', 'fairy', 'world', 'and', 'that', 'there', 'are', 'others', 'after', 'her', 'too', 'three', 'elderly', 'witches', 'who', 'want', 'to', 'use', 'her', 'heart', 'to', 'become', 'young', 'again', 'and', 'some', 'bickering', 'princes', 'its', 'a', 'really', 'good', 'story', 'it', 'has', 'humor', 'and', 'magic', 'and', 'beautiful', 'surreal', 'scenes', 'and', 'visuals', 'its', 'charming', 'and', 'i', 'feel', 'it', 'can', 'be', 'watched', 'by', 'children', 'and', 'adults', 'of', 'all', 'ages', 'its', 'simply', 'magical', 'its', 'a', 'true', 'classic', 'fairy', 'tale', 'the', 'likes', 'of', 'which', 'i', 'havent', 'seen', 'in', 'cinema', 'since', 'the', '1980s'], ['this', 'film', 'might', 'have', 'weak', 'production', 'values', 'but', 'that', 'is', 'also', 'what', 'makes', 'it', 'so', 'good', 'the', 'special', 'effects', 'are', 'gross', 'out', 'and', 'well', 'done', 'my', 'favorite', 'part', 'of', 'the', 'movie', 'had', 'to', 'be', 'chrissy', 'played', 'by', 'janelle', 'brady', 'she', 'is', 'super', 'hot', 'and', 'also', 'has', 'a', 'good', 'nude', 'scene', 'robert', 'prichard', 'as', 'the', 'leader', 'of', 'the', 'gang', 'is', 'hilarious', 'as', 'are', 'the', 'other', 'members', 'this', 'film', 'is', 'actually', 'trying', 'to', 'make', 'a', 'point', 'by', 'saying', 'that', 'nuclear', 'waste', 'plants', 'are', 'bad', '4', '10', 'fair', 'comedy', 'gross', 'out', 'film']]\n"
     ]
    }
   ],
   "source": [
    "print(processed_corpus[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Word2Vec\n",
    "See other parameters at https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "w2vmodel = Word2Vec(sentences=processed_corpus,\n",
    "                    size=300,\n",
    "                    min_count=5,\n",
    "                    workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erickmaziero/virtualenvs/NLP-IA_env/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('actor', 0.7551474571228027),\n",
       " ('performer', 0.573062539100647),\n",
       " ('role', 0.5399695634841919),\n",
       " ('comedian', 0.5142716765403748),\n",
       " ('performance', 0.5095571875572205),\n",
       " ('artist', 0.47670966386795044),\n",
       " ('villain', 0.45249801874160767),\n",
       " ('singer', 0.42914724349975586),\n",
       " ('oscar', 0.4257918894290924),\n",
       " ('achievement', 0.4153568744659424)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.most_similar(positive=['actress', 'man'], negative=['woman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('godzilla', 0.6869165301322937),\n",
       " ('phantasm', 0.5817844867706299),\n",
       " ('twilight', 0.5758272409439087),\n",
       " ('godfather', 0.5639734864234924),\n",
       " ('blade', 0.5633026361465454),\n",
       " ('hostel', 0.561491847038269),\n",
       " ('phantom', 0.5545967817306519),\n",
       " ('conan', 0.544568657875061),\n",
       " ('wars', 0.5444141626358032),\n",
       " ('craze', 0.5411075353622437)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.most_similar('matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25333130e+00,  7.25100219e-01, -3.39769006e-01, -1.11589932e+00,\n",
       "        4.39446926e-01, -7.25901067e-01,  9.25769925e-01, -4.58653897e-01,\n",
       "       -1.70235968e+00,  8.19877088e-01,  1.07927121e-01, -4.51163709e-01,\n",
       "        1.87763906e+00,  7.80995131e-01, -5.41266561e-01, -1.27781188e+00,\n",
       "        1.20189083e+00, -2.92429864e-01,  1.18349063e+00, -5.95851243e-01,\n",
       "        3.48397017e-01,  4.78480399e-01,  1.95853043e+00, -1.31650472e+00,\n",
       "       -9.05684352e-01,  7.20012367e-01, -1.99470270e+00,  1.34943461e+00,\n",
       "        3.70051146e-01,  1.87643504e+00,  2.03323984e+00,  4.12070066e-01,\n",
       "        8.53172839e-01, -1.07866945e-03,  6.12409413e-01,  4.72545207e-01,\n",
       "        1.67925611e-01,  1.57392204e-01,  2.67814130e-01, -6.30028665e-01,\n",
       "        1.52726376e+00,  8.71291816e-01, -1.98622167e-01, -3.32597882e-01,\n",
       "        2.53938913e-01,  9.69515920e-01, -5.53712785e-01,  1.38318050e+00,\n",
       "        1.19589925e+00,  1.99329138e+00,  1.39446747e+00, -2.60554552e-01,\n",
       "       -2.44315267e-01, -7.13956654e-01,  6.70270026e-02, -1.84416187e+00,\n",
       "        7.16575205e-01,  1.20032752e+00, -6.44488037e-01,  7.78760970e-01,\n",
       "       -6.75036609e-02,  1.54304361e+00, -1.54064000e+00, -7.52934337e-01,\n",
       "        1.17232311e+00,  6.01164877e-01, -1.00598681e+00,  1.18383065e-01,\n",
       "       -5.61362863e-01, -8.30183566e-01, -5.89493275e-01, -5.23415923e-01,\n",
       "       -7.01090932e-01, -7.27450028e-02,  1.67784333e+00, -5.56886077e-01,\n",
       "       -2.26223063e+00, -4.73528713e-01, -6.70930922e-01, -3.01743484e+00,\n",
       "        1.49053931e+00, -1.59976983e+00,  1.70445889e-01, -1.64519715e+00,\n",
       "        1.45261729e+00,  5.78354657e-01, -1.68644595e+00, -9.36724767e-02,\n",
       "        2.83989102e-01,  2.72699237e-01,  8.59955609e-01, -2.32873425e-01,\n",
       "        1.18332356e-01, -1.16143644e+00, -1.28345931e+00, -5.14346123e-01,\n",
       "       -3.84940475e-01, -8.06647241e-01, -3.17584425e-01,  1.91393957e-01,\n",
       "        5.86091101e-01,  2.16551751e-01, -1.54831040e+00,  3.98826152e-01,\n",
       "        6.47116542e-01, -1.08579981e+00,  4.59709913e-01, -4.76765245e-01,\n",
       "       -8.07014287e-01,  4.36068356e-01, -8.64360511e-01,  2.82921702e-01,\n",
       "       -4.00807798e-01, -1.19705725e+00, -1.23699999e+00, -7.18959048e-02,\n",
       "        7.33021736e-01,  3.41304958e-01,  8.69850934e-01, -1.19343781e+00,\n",
       "       -3.22300638e-03,  3.84957224e-01,  1.50681615e+00, -2.37828538e-01,\n",
       "       -9.42324460e-01,  8.78783464e-01, -4.90281552e-01,  1.86044073e+00,\n",
       "        1.61816308e-03,  1.56887305e+00, -6.12053335e-01, -1.28226244e+00,\n",
       "        8.43777001e-01,  1.38017786e+00,  2.79780626e-01, -6.28189087e-01,\n",
       "        1.78763664e+00,  4.93879497e-01,  1.33678198e+00,  5.47160327e-01,\n",
       "        5.64993825e-03,  4.95463051e-02,  2.13690257e+00,  7.23696828e-01,\n",
       "        1.14646959e+00, -2.05155802e+00, -2.96656508e-02, -1.49920809e+00,\n",
       "        7.18361378e-01,  1.30616546e+00,  3.21130127e-01, -8.09882998e-01,\n",
       "       -8.13547552e-01, -1.31126869e+00,  5.85584581e-01,  6.94999039e-01,\n",
       "       -2.13087654e+00,  1.63177416e-01, -4.91127163e-01, -1.22921228e-01,\n",
       "       -1.04940462e+00, -1.74940929e-01, -1.21945548e+00,  1.74615070e-01,\n",
       "       -2.43477955e-01, -9.16013956e-01,  1.66595906e-01, -4.71974403e-01,\n",
       "        1.65001988e+00, -5.55341363e-01,  1.41117060e+00, -5.05255759e-01,\n",
       "        8.39954674e-01, -1.61220515e+00, -1.17771065e+00,  8.88046459e-04,\n",
       "       -7.48929262e-01,  1.23345435e+00, -1.04104141e-02,  2.02386472e-02,\n",
       "       -1.23658395e+00, -6.23123109e-01,  3.80075201e-02,  8.42224240e-01,\n",
       "        1.03788579e+00,  2.72635508e+00, -4.36481148e-01, -9.85716641e-01,\n",
       "       -1.47185302e+00,  1.32779217e+00, -1.55449748e+00,  7.46648967e-01,\n",
       "       -7.38228917e-01,  4.00007933e-01,  1.85206294e-01, -5.95806479e-01,\n",
       "        1.12641007e-01,  1.40521133e+00,  8.89536917e-01, -8.94945145e-01,\n",
       "        8.36791873e-01,  1.75480330e+00, -2.41002128e-01, -2.99445540e-01,\n",
       "       -3.30790758e-01,  3.81362528e-01, -1.37109816e-01, -1.77922571e+00,\n",
       "       -1.30728722e+00, -3.68609816e-01,  3.03500175e+00,  4.74983096e-01,\n",
       "        6.98481083e-01, -2.43123078e+00, -2.74247944e-01,  5.56720734e-01,\n",
       "       -1.26088834e+00,  3.93870354e-01,  5.19340575e-01,  2.50404745e-01,\n",
       "       -6.27688706e-01,  5.51937759e-01, -6.66596293e-01,  8.90304446e-02,\n",
       "        1.16188180e+00,  2.00446807e-02, -1.52185655e+00,  9.30391729e-01,\n",
       "        1.44805133e+00,  2.71164060e-01, -7.56673396e-01,  5.84231555e-01,\n",
       "       -6.55608714e-01,  3.56139004e-01,  7.11746871e-01, -1.14095497e+00,\n",
       "       -8.24333191e-01,  1.47977129e-01,  9.64364469e-01, -2.13770866e+00,\n",
       "        1.87038255e+00, -8.52403998e-01, -4.48377460e-01, -1.07407784e+00,\n",
       "        6.47908330e-01,  4.33870196e-01, -1.14004457e+00, -1.36041880e-01,\n",
       "        9.41199481e-01,  4.70378786e-01,  4.44084257e-01,  3.62153053e-01,\n",
       "        1.02938354e+00, -1.51924944e+00, -8.34786832e-01, -4.65482503e-01,\n",
       "       -2.38338614e+00, -1.64337009e-02,  3.73184830e-01,  1.98134148e+00,\n",
       "        5.26005089e-01,  9.73081648e-01, -2.56177604e-01, -1.17001593e+00,\n",
       "        1.93840134e+00,  6.43986583e-01,  1.06551087e+00, -9.49300230e-01,\n",
       "        1.72883046e+00, -5.73167801e-01, -3.02775145e-01, -1.19321382e+00,\n",
       "       -1.34768188e-01, -1.95074201e+00, -4.04641569e-01, -1.67316163e+00,\n",
       "       -1.35663778e-01,  5.10179639e-01,  6.35458589e-01, -5.67990124e-01,\n",
       "       -2.07131219e+00,  1.66554654e+00,  1.23501949e-01,  5.18063962e-01,\n",
       "        8.63461375e-01,  1.34963715e+00,  2.94788688e-01,  1.35658717e+00,\n",
       "       -1.12801898e+00,  1.66788709e+00, -1.65440190e+00,  1.50854313e+00,\n",
       "        1.11282384e+00, -3.64075631e-01, -1.02483106e+00, -1.12807758e-01,\n",
       "       -2.55270898e-01,  1.97301912e+00, -9.39187109e-01, -6.78270221e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vmodel.wv.get_vector('movie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get infos from w2v model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(w2vmodel.wv.vocab)\n",
    "X = w2vmodel[vocab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### project n-dimensional into 2-dimensional space using T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, n_iter=250)\n",
    "X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a dataframe and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_tsne, index=vocab, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.scatter(df['x'], df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, pos in df.iterrows():\n",
    "    ax.annotate(word, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
